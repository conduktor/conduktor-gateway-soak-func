title: ClusterSwitching
services:
  kafka1:
    environment:
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
    properties:
      bootstrap.servers: localhost:29092,localhost:29093,localhost:29094
  kafka2:
    environment:
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
    properties:
      bootstrap.servers: localhost:29092,localhost:29093,localhost:29094
  kafka3:
    environment:
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
    properties:
      bootstrap.servers: localhost:29092,localhost:29093,localhost:29094
  failover-kafka1:
    docker:
      hostname: failover-kafka1
      container_name: failover-kafka1
      image: confluentinc/cp-kafka:latest
      ports:
        - "39092:39092"
      environment:
        KAFKA_BROKER_ID: 1
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2801/backup
        KAFKA_LISTENERS: EXTERNAL_SAME_HOST://:39092,INTERNAL://:9092
        KAFKA_ADVERTISED_LISTENERS: EXTERNAL_SAME_HOST://localhost:39092,INTERNAL://failover-kafka1:9092
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL_SAME_HOST:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
        KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        KAFKA_LOG4J_LOGGERS: "kafka.authorizer.logger=INFO"
        KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
      depends_on:
        zookeeper:
          condition: service_healthy
      healthcheck:
        test: nc -zv failover-kafka1 9092 || exit 1
        interval: 5s
        retries: 25
    properties:
      bootstrap.servers: localhost:39092,localhost:39093,localhost:39094
  failover-kafka2:
    docker:
      hostname: failover-kafka2
      container_name: failover-kafka2
      image: confluentinc/cp-kafka:latest
      ports:
        - "39093:39093"
      environment:
        KAFKA_BROKER_ID: 2
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2801/backup
        KAFKA_LISTENERS: EXTERNAL_SAME_HOST://:39093,INTERNAL://:9093
        KAFKA_ADVERTISED_LISTENERS: EXTERNAL_SAME_HOST://localhost:39093,INTERNAL://failover-kafka2:9093
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL_SAME_HOST:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
        KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        KAFKA_LOG4J_LOGGERS: "kafka.authorizer.logger=INFO"
        KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
      depends_on:
        zookeeper:
          condition: service_healthy
      healthcheck:
        test: nc -zv failover-kafka2 9093 || exit 1
        interval: 5s
        retries: 25
    properties:
      bootstrap.servers: localhost:39092,localhost:39093,localhost:39094
  failover-kafka3:
    docker:
      hostname: failover-kafka3
      container_name: failover-kafka3
      image: confluentinc/cp-kafka:latest
      ports:
        - "39094:39094"
      environment:
        KAFKA_BROKER_ID: 3
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2801/backup
        KAFKA_LISTENERS: EXTERNAL_SAME_HOST://:39094,INTERNAL://:9094
        KAFKA_ADVERTISED_LISTENERS: EXTERNAL_SAME_HOST://localhost:39094,INTERNAL://failover-kafka3:9094
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL_SAME_HOST:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
        KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        KAFKA_LOG4J_LOGGERS: "kafka.authorizer.logger=INFO"
        KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
      depends_on:
        zookeeper:
          condition: service_healthy
      healthcheck:
        test: nc -zv failover-kafka3 9094 || exit 1
        interval: 5s
        retries: 25
    properties:
      bootstrap.servers: localhost:39092,localhost:39093,localhost:39094
  mirror-maker:
    docker:
      image: confluentinc/cp-kafka:latest
      container_name: mirror-maker
      hostname: mirror-maker
      volumes:
        - type: bind
          source: "../config"
          target: /config
          read_only: true
      command: sleep infinity
      depends_on:
        kafka1:
          condition: service_healthy
        kafka2:
          condition: service_healthy
        kafka3:
          condition: service_healthy
        failover-kafka1:
          condition: service_healthy
        failover-kafka2:
          condition: service_healthy
        failover-kafka3:
          condition: service_healthy
      healthcheck:
        test: nc -zv failover-kafka3 9094 || exit 1
        interval: 5s
        retries: 25
  gateway1:
    docker:
      image: conduktor/conduktor-gateway:2.1.4
      environment:
        GATEWAY_ADVERTISED_HOST: localhost
        GATEWAY_FEATURE_FLAGS_MULTI_TENANCY: true
        GATEWAY_SECURITY_PROTOCOL: SASL_PLAINTEXT
        GATEWAY_CLUSTER_ID: private
        GATEWAY_BACKEND_KAFKA_SELECTOR: 'file : { path:  /config/cluster-switching-clusters.yaml}'
      volumes:
        - type: bind
          source: "../config"
          target: /config
          read_only: true
    properties:
      bootstrap.servers: localhost:6969
      gateway.host: http://localhost:8888

  gateway2:
    docker:
      image: conduktor/conduktor-gateway:2.1.4
      environment:
        GATEWAY_ADVERTISED_HOST: localhost
        GATEWAY_FEATURE_FLAGS_MULTI_TENANCY: true
        GATEWAY_SECURITY_PROTOCOL: SASL_PLAINTEXT
        GATEWAY_CLUSTER_ID: private
        GATEWAY_BACKEND_KAFKA_SELECTOR: 'file : { path:  /config/cluster-switching-clusters.yaml}'
      volumes:
        - type: bind
          source: "../config"
          target: /config
          read_only: true
    properties:
      bootstrap.servers: localhost:6969
      gateway.host: http://localhost:8889

actions:

  - type: DOCKER
    title: Start all
    command: docker compose up -d --wait

  - type: DOCKER
    title: Start mirror maker
    daemon: true
    command: |
      docker compose exec -ti mirror-maker \
        connect-mirror-maker \
          /config/mm2.properties &

  - type: CREATE_VIRTUAL_CLUSTERS
    title: Create teamA virtual cluster
    gateway: gateway1
    name: teamA

  - type: CREATE_TOPICS
    title: Create topic users
    kafka: teamA
    kafkaConfig: teamA-sa.properties
    topics:
      - name: users
        replicationFactor: 1
        partitions: 1

  - type: PRODUCE
    title: Send tom and florent into topic users
    kafka: teamA
    kafkaConfig: teamA-sa.properties
    topic: users
    messages:
      - value: '{"name":"tom","username":"tom@conduktor.io","password":"motorhead","visa":"#abc123","address":"Chancery lane, London"}'
      - value: '{"name":"florent","username":"florent@conduktor.io","password":"kitesurf","visa":"#888999XZ","address":"Dubai, UAE"}'

  - type: LIST_TOPICS
    kafka: kafka1
    assertExists:
      - _acls
      - _auditLogs
      - _consumerGroupSubscriptionBackingTopic
      - _interceptorConfigs
      - _license
      - _offsetStore
      - _schemas
      - _topicMappings
      - _topicRegistry
      - teamAusers

  - type: CONSUME
    title: Wait for mirror maker to do its job on gateway internal topic
    kafka: failover-kafka1
    maxMessages: 1
    topic: _topicMappings

  - type: CONSUME
    title: Wait for mirror maker to do its job on user topics
    kafka: failover-kafka1
    maxMessages: 1
    topic: teamAusers

  - type: LIST_TOPICS
    title: Assert mirror maker did its job
    kafka: failover-kafka1
    assertExists:
      - _acls
      - _auditLogs
      - _consumerGroupSubscriptionBackingTopic
      - _interceptorConfigs
      - _license
      - _offsetStore
      - _schemas
      - _topicMappings
      - _topicRegistry
      - teamAusers

  - type: FAILOVER
    title: Call the failover switch api on gateway1
    gateway: gateway1
    from: main
    to: failover

  - type: FAILOVER
    title: Call the failover switch api on gateway2
    gateway: gateway2
    from: main
    to: failover

  - type: PRODUCE
    title: Produce thibault into users, it should hit only failover-kafka
    kafka: teamA
    kafkaConfig: teamA-sa.properties
    topic: users
    messages:
      - value: '{"name":"thibaut","username":"thibaut@conduktor.io","password":"youpi","visa":"#812SSS","address":"Les ifs"}'

  - type: CONSUME
    title: Verify we can read florent, and tom (via mirror maker) and thibault (via switch)
    kafka: teamA
    kafkaConfig: teamA-sa.properties
    topic: users
    maxMessages: 3
    assertSize: 3
    assertions:
      - description: Confirm producer after switch is readable
        value:
          operator: containsIgnoreCase
          expected: 'thibaut'

  - type: CONSUME
    title: Verify thibaut is not in main kafka
    kafka: kafka1
    topic: teamAusers
    assertSize: 2
    assertions:
      - description: Thibaut should be only in failover kafka
        value:
          operator: doesNotContainIgnoringCase
          expected: 'thibaut'

  - type: CONSUME
    title: Verify thibaut is in failover
    kafka: failover-kafka1
    topic: teamAusers
    maxMessages: 3
    assertions:
      - description: Confirm producer after switch is written in failover kafka
        value:
          operator: containsIgnoreCase
          expected: 'thibaut'