title: ClusterSwitching
services:
  kafka1:
    environment:
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
    properties:
      bootstrap.servers: localhost:29092,localhost:29093,localhost:29094
      auto.offset.reset: earliest
      enable.auto.commit: false
      client.id: clientId
  kafka2:
    environment:
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
    properties:
      bootstrap.servers: localhost:29092,localhost:29093,localhost:29094
      auto.offset.reset: earliest
      enable.auto.commit: false
      client.id: clientId
  kafka3:
    environment:
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
    properties:
      bootstrap.servers: localhost:29092,localhost:29093,localhost:29094
      auto.offset.reset: earliest
      enable.auto.commit: false
      client.id: clientId
  failover-kafka1:
    docker:
      hostname: failover-kafka1
      container_name: failover-kafka1
      image: confluentinc/cp-kafka:latest
      ports:
        - "39092:39092"
      environment:
        KAFKA_BROKER_ID: 1
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2801/backup
        KAFKA_LISTENERS: EXTERNAL_SAME_HOST://:39092,INTERNAL://:9092
        KAFKA_ADVERTISED_LISTENERS: EXTERNAL_SAME_HOST://localhost:39092,INTERNAL://failover-kafka1:9092
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL_SAME_HOST:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
        KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        KAFKA_LOG4J_LOGGERS: "kafka.authorizer.logger=INFO"
        KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
      depends_on:
        zookeeper:
          condition: service_healthy
      healthcheck:
        test: nc -zv failover-kafka1 9092 || exit 1
        interval: 5s
        retries: 25
    properties:
      bootstrap.servers: localhost:39092,localhost:39093,localhost:39094
      auto.offset.reset: earliest
      enable.auto.commit: false
      client.id: failover-clientId
  failover-kafka2:
    docker:
      hostname: failover-kafka2
      container_name: failover-kafka2
      image: confluentinc/cp-kafka:latest
      ports:
        - "39093:39093"
      environment:
        KAFKA_BROKER_ID: 2
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2801/backup
        KAFKA_LISTENERS: EXTERNAL_SAME_HOST://:39093,INTERNAL://:9093
        KAFKA_ADVERTISED_LISTENERS: EXTERNAL_SAME_HOST://localhost:39093,INTERNAL://failover-kafka2:9093
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL_SAME_HOST:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
        KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        KAFKA_LOG4J_LOGGERS: "kafka.authorizer.logger=INFO"
        KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
      depends_on:
        zookeeper:
          condition: service_healthy
      healthcheck:
        test: nc -zv failover-kafka2 9093 || exit 1
        interval: 5s
        retries: 25
    properties:
      bootstrap.servers: localhost:39092,localhost:39093,localhost:39094
      auto.offset.reset: earliest
      enable.auto.commit: false
      client.id: failover-clientId
  failover-kafka3:
    docker:
      hostname: failover-kafka3
      container_name: failover-kafka3
      image: confluentinc/cp-kafka:latest
      ports:
        - "39094:39094"
      environment:
        KAFKA_BROKER_ID: 3
        KAFKA_ZOOKEEPER_CONNECT: zookeeper:2801/backup
        KAFKA_LISTENERS: EXTERNAL_SAME_HOST://:39094,INTERNAL://:9094
        KAFKA_ADVERTISED_LISTENERS: EXTERNAL_SAME_HOST://localhost:39094,INTERNAL://failover-kafka3:9094
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL_SAME_HOST:PLAINTEXT
        KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
        KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
        KAFKA_LOG4J_LOGGERS: "kafka.authorizer.logger=INFO"
        KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: false
      depends_on:
        zookeeper:
          condition: service_healthy
      healthcheck:
        test: nc -zv failover-kafka3 9094 || exit 1
        interval: 5s
        retries: 25
    properties:
      bootstrap.servers: localhost:39092,localhost:39093,localhost:39094
      auto.offset.reset: earliest
      enable.auto.commit: false
      client.id: failover-clientId
  mirror-maker:
    docker:
      image: confluentinc/cp-kafka:latest
      container_name: mirror-maker
      hostname: mirror-maker
      volumes:
        - type: bind
          source: "../config"
          target: /config
          read_only: true
      command: sleep infinity
      depends_on:
        kafka1:
          condition: service_healthy
        kafka2:
          condition: service_healthy
        kafka3:
          condition: service_healthy
        failover-kafka1:
          condition: service_healthy
        failover-kafka2:
          condition: service_healthy
        failover-kafka3:
          condition: service_healthy
      healthcheck:
        test: nc -zv failover-kafka3 9094 || exit 1
        interval: 5s
        retries: 25
  gateway1:
    docker:
      image: conduktor/conduktor-gateway:2.1.4
      environment:
        GATEWAY_ADVERTISED_HOST: localhost
        GATEWAY_FEATURE_FLAGS_MULTI_TENANCY: true
        GATEWAY_SECURITY_PROTOCOL: SASL_PLAINTEXT
        GATEWAY_CLUSTER_ID: private
        GATEWAY_BACKEND_KAFKA_SELECTOR: 'file : { path:  /config/cluster-switching-clusters.yaml}'
      volumes:
        - type: bind
          source: "../config"
          target: /config
          read_only: true
    properties:
      bootstrap.servers: localhost:6969,localhost:7969
      auto.offset.reset: earliest
      enable.auto.commit: false
      client.id: gateway1-clientId

  gateway2:
    docker:
      image: conduktor/conduktor-gateway:2.1.4
      environment:
        GATEWAY_ADVERTISED_HOST: localhost
        GATEWAY_FEATURE_FLAGS_MULTI_TENANCY: true
        GATEWAY_SECURITY_PROTOCOL: SASL_PLAINTEXT
        GATEWAY_CLUSTER_ID: private
        GATEWAY_BACKEND_KAFKA_SELECTOR: 'file : { path:  /config/cluster-switching-clusters.yaml}'
      volumes:
        - type: bind
          source: "../config"
          target: /config
          read_only: true
    properties:
      bootstrap.servers: localhost:6969,localhost:7969
      auto.offset.reset: earliest
      enable.auto.commit: false
      client.id: gateway2-clientId

actions:

  - type: BASH
    description: Start mirror maker
    script: |
      docker compose exec mirror-maker connect-mirror-maker -daemon /config/mm2.properties


  - type: CREATE_VIRTUAL_CLUSTERS
    gateway: gateway1
    names:
      - teamA

  - type: CREATE_TOPICS
    description: create topic users
    kafka: teamA
    topics:
      - name: users
        replicationFactor: 1
        partitions: 1

  - type: PRODUCE
    description: send tom and florent into topic users
    kafka: teamA
    topic: users
    messages:
      - value: '{"name":"tom","username":"tom@conduktor.io","password":"motorhead","visa":"#abc123","address":"Chancery lane, London"}'
      - value: '{"name":"florent","username":"florent@conduktor.io","password":"kitesurf","visa":"#888999XZ","address":"Dubai, UAE"}'

  - type: LIST_TOPICS
    kafka: kafka1
    assertExists:
      - _acls
      - _auditLogs
      - _consumerGroupSubscriptionBackingTopic
      - _interceptorConfigs
      - _license
      - _offsetStore
      - _schemas
      - _topicMappings
      - _topicRegistry
      - teamAusers

  - type: BASH
    description: Wait for mirror maker to do its job
    showOutput: true
    kafka: failover-kafka1
    script: |
      docker compose exec failover-kafka1 kafka-console-consumer --bootstrap-server localhost:9092 --topic _topicMappings --from-beginning --max-messages 1
      docker compose exec failover-kafka1 kafka-console-consumer --bootstrap-server localhost:9092 --topic teamAusers --from-beginning --max-messages 1


  - type: LIST_TOPICS
    description: assert mirror maker did its job
    kafka: failover-kafka1
    assertExists:
      - _acls
      - _auditLogs
      - _consumerGroupSubscriptionBackingTopic
      - _interceptorConfigs
      - _license
      - _offsetStore
      - _schemas
      - _topicMappings
      - _topicRegistry
      - teamAusers

  - type: BASH
    description: Call the switch api
    showOutput: true
    script: |
      curl \
        --silent \
        --user "admin:conduktor" \
        --request POST 'http://localhost:8888/admin/pclusters/v1/pcluster/main/switch?to=failover'
      curl \
        --silent \
        --user "admin:conduktor" \
        --request POST 'http://localhost:8889/admin/pclusters/v1/pcluster/main/switch?to=failover'

      echo "Sleeping for the failover to do its thing"
      sleep 20

  - type: PRODUCE
    description: produce thibault into users, it should hit only failover-kafka
    kafka: teamA
    topic: users
    messages:
      - value: '{"name":"thibaut","username":"thibaut@conduktor.io","password":"youpi","visa":"#812SSS","address":"Les ifs"}'

  - type: CONSUME
    description: verify we can read florent, and tom (via mirror maker) and thibault (via switch)
    kafka: teamA
    properties:
      auto.offset.reset: earliest
    topics:
      - users
    assertSize: 3
    assertions:
      - description: confirm producer after switch is readable
        value:
          operator: containsIgnoreCase
          expected: 'thibaut'

  - type: CONSUME
    description: verify thibaut is not in main kafka
    kafka: kafka1
    properties:
      auto.offset.reset: earliest
    topics:
      - teamAusers
    assertSize: 2
    assertions:
      - description: Thibaut should be only in failover kafka
        value:
          operator: doesNotContainIgnoringCase
          expected: 'thibaut'

  - type: CONSUME
    description: verify thibaut is in failover
    kafka: failover-kafka1
    properties:
      auto.offset.reset: earliest
    topics:
      - teamAusers
    assertions:
      - description: confirm producer after switch is written in failover kafka
        value:
          operator: containsIgnoreCase
          expected: 'thibaut'